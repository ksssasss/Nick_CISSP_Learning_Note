# 大語言模型開發與安全

## 1. 開發生命週期

### 資料工程
- 資料工程是基礎科學，包含資料截取、遣除、儲存和管理
- 在大語言模型領域，解決方案有所不同，例如使用 embedding 計算相似度
- 資料品質直接影響模型表現，是整個流程的基礎

### 預訓練
- 企業自行訓練模型成本高昂，主要來自 GPU 運算
- 重要考量：
  - Tokenizer 選擇：影響模型品質
  - Checkpointing：防止訓練中斷
  - 模型版本管理：記錄訓練資料集來源

### 基礎模型選擇
- 兩個主要選擇：
  - 使用開源模型自行調整
  - 選擇 LLM 供應商的 SaaS 服務（如 OpenAI、Cloud Entropy）
- 選擇考量：控制程度、後續維護成本、SLA 需求

### 領域適配
- 三種方法（成本由低到高）：
  - Prompt Engineering：使用合適的提示詞引導 AI
  - RAG（Retrieval-Augmented Generation）：提供參考資料
  - Fine-tuning：將通用模型轉為專業模型

### 評估
- 評估方法（成本由低到高）：
  - 指標性評估
  - 工資性評估
  - 模型式評估
  - 人類評估
- 通常採用混合方法，先用機器學習過濾，必要時加入人工評估

### 應用開發與整合
- 常用框架：Langchain、Lama Index、Hashtag
- 開發工具支援：NCT 協定（Cursor、VS Code Client、Cloud Desktop）

### 部署與監控
- 部署考量：
  - 部署模式（雲端/本地）
  - 部署方法（藍綠部署、金絲雀發布）
- 監控工具：
  - OpenTelemetry
  - LandFuse（基於 OpenTelemetry）

## 2. 安全風險與防禦

### 主要安全風險
1. Prompt Injection
   - 攻擊手法：
     - 強制性指令
     - 反向心理學
     - 情感操控（如 Grandma Probe）
   - 傳輸途徑：
     - 直接傳輸
     - 間接傳輸（如網路爬文）

2. 資料洩漏
   - 資料獲取途徑：
     - 模型訓練資料
     - RAG 過程
     - 使用者輸入
   - 案例：韓國聊天機器人洩漏個人資料

3. Hallucination（幻覺）
   - 原因：AI 在缺乏完整資訊時自行推論
   - 風險：可能提供錯誤或不存在的資訊
   - 案例：Stack Overflow 上的虛假套件推薦

### 安全防禦方法論（DIRM）
1. Layer（分層識別）
   - 識別應用程式的風險層級
   - 建立多層次安全檢查

2. Evaluate（評估）
   - 評估應用程式可能面臨的風險
   - 確定安全邊界

3. Act（行動）
   - 根據風險評估採取對應防禦措施
   - 實施安全控制

4. Reinforcement（強化）
   - 持續監控
   - 根據回饋完善防禦機制

5. Neutral（教育）
   - 提供安全意識培訓
   - 建立安全文化

## 3. 重要注意事項
- 資料品質是模型表現的關鍵
- 預訓練成本高昂，需謹慎評估
- 需要持續監控和評估模型表現
- 企業需對 AI 系統的輸出負責
- 安全風險會發生在信任度變化的邊界
- 定期更新安全白皮書和最佳實踐 